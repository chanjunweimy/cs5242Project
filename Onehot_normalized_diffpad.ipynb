{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def load_train_dataframe(id):\n",
    "    train_data = np.load(\"train/train/{}.npy\".format(id))\n",
    "    return pd.DataFrame(data=train_data)\n",
    "def load_test_dataframe(id):\n",
    "    test_data = np.load(\"test/test/{}.npy\".format(id))\n",
    "    return pd.DataFrame(data=test_data)\n",
    "\n",
    "# load training\n",
    "traindata = []\n",
    "for id in df_train['Id']:\n",
    "    dfi = load_train_dataframe(id)\n",
    "    traindata.append(dfi.values)\n",
    "print('Done train')\n",
    "# load test\n",
    "testdata = []\n",
    "for id in df_test['Id']:\n",
    "    dfi = load_test_dataframe(id)\n",
    "    testdata.append(dfi.values)\n",
    "print('Done test')\n",
    "\n",
    "np.save('traindata.npy', traindata)\n",
    "\n",
    "np.save('testdata.npy', testdata)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "training data:  (18662, 2) \n",
      "test data:  (6051, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print('Done')\n",
    "df_train = pd.read_csv('train_kaggle.csv')\n",
    "df_test = pd.read_csv('sample_solution.csv')\n",
    "\n",
    "print('training data: ',df_train.shape,'\\ntest data: ', df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def process(dfs):\n",
    "    data = []\n",
    "    for df in dfs:\n",
    "        out = np.zeros((df.shape[0],74+1))\n",
    "        out[:,0:8] = df[:,0:8]\n",
    "        out[:,8:12] = df[:,8:12]\n",
    "        out[:,12:28] = df[:,12:28]\n",
    "        out[:,28:44] = df[:,28:44]\n",
    "        out[:,44:52] = df[:,44:52]\n",
    "        out[:,52:64] = df[:,52:64]\n",
    "    #     out[:,6] = dfs[:,64:80].sum(axis=1) ignore\n",
    "    #     out[:,7] = dfs[:,80:92].sum(axis=1) ignore\n",
    "        out[:,64:74] = df[:,92:102]\n",
    "        out[:,74] = df.shape[0]/100 # Store length of the data\n",
    "        data.append(out)                 \n",
    "    return data\n",
    "\n",
    "def pad_data(dfs):\n",
    "    padsize = 500\n",
    "    data = []\n",
    "    for df in dfs:\n",
    "        diff = padsize-df.shape[0]\n",
    "        if diff >0:\n",
    "            df = np.pad(df, [(diff, 0), (0,0)], 'constant') # I use padding on the front, focus on learning from the back\n",
    "        else:\n",
    "            df = df[-padsize:]\n",
    "        data.append(df)\n",
    "        \n",
    "    data = np.stack(data)\n",
    "    for i in range(data.shape[0]):\n",
    "        data[i,:,:] = normalize(data[i,:,:],axis=0) # Data normalized (Minimal effect)\n",
    "    return data\n",
    "\n",
    "# Load data + Process + Pad\n",
    "xtrain = np.load('traindata.npy',allow_pickle=True)\n",
    "xtrain = process(xtrain)\n",
    "xtrain = pad_data(xtrain)\n",
    "# xtest = np.load('testdata.npy',allow_pickle=True)\n",
    "# xtest = process(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([       0,  1000000, 21100101, 41000001,  1001010, 41000001,\n",
       "              0,    10100, 41000001,  1001010, 41000001,        0,\n",
       "        2010012, 41000001,  1001010, 41000001,        0,  2010102,\n",
       "       41000001,  1001010, 41000001,        0,  1010200,  2010012,\n",
       "        2010102,  1010200,  2010012,  2010102,  1010200, 41000001,\n",
       "        1001010, 41000001,        0,  2010012,  2010102,  1010200,\n",
       "       41000001,  1001010, 41000001,        0,   120000, 41000001,\n",
       "        1001010, 41000001,        0,  1011120,  1010100,  1010302,\n",
       "        1010302,  1010302,  1010302,  1010302,  1010302,  1010302,\n",
       "        1010302,  1010302,  1010302,  1010302,  1010302,  1010302,\n",
       "        1010302,  1010302,  1010302,  1010302,  1010302,  1010200,\n",
       "        1010100,  1010100,  1010100,  1010100,  1010302,  1010200,\n",
       "       23002031,        0,  1010100,  1010100,  1010200,  1010302,\n",
       "        1010200,  1010100,  1010100,  1010200,  1010302,  1010200,\n",
       "              0,  2010001,  1010100,  1010100,  1010200,  1010302,\n",
       "        1010200,  1010100,  1001010,        0,  1000200,  1010100,\n",
       "        1010302,  1010200,  1000200,  1010200,        0,  1010100,\n",
       "        1010100, 22010010,  2010001, 21010100,  2010001,        0,\n",
       "       21011010,  2010300,  2010300,    10011, 22010010,        0,\n",
       "              0,  1010100,  1010302,  1010302, 20000103,  1010100,\n",
       "        1010302,  1010200,  1010100,  1010302,  1010200,  1010100,\n",
       "        1010302,  1010200,  1001010,        0,  1010200,  2010001,\n",
       "              0,  2010110,  2010001, 22010100,  2010300, 22010010,\n",
       "        2010001,  2010110,  2010001, 22010100,        0,        0,\n",
       "       20000103,  2010300, 22010100, 20000103,  2010001,  2010001,\n",
       "        2010101, 22010010, 20010110, 22010010, 20230300,  2010001,\n",
       "       20000103,        0, 20000103,  1010100,  1010302,  1010200,\n",
       "        1010100,  1010100,  1010302,  1010302,  1010200,  1010100,\n",
       "        1010302,  1010200,  1010100,  1010100,  1010302,  1010200,\n",
       "        1010100,  1010100,  1010302,  1010200,  1010100,  1010100,\n",
       "        1010302,  1010200,  1010100,  1010100,  1010302,  1010200,\n",
       "        1010100,  1010100,  1010302,  1010302,  1010302,  1010302,\n",
       "        1010302,  1010302,  1010302,  1010302,  1010302,  1010302,\n",
       "        1010302,  1010302,  1010302,  1010302,  1010302,  1010200,\n",
       "        1001010,        0,  1010100,  1010100,  1010100,  1010100,\n",
       "        1010100,  1010200,  1010100,  1010200,  1010100,  1010100,\n",
       "        1010100,  1010100,  1010100,  1010302,  1010100,  1010302,\n",
       "        1010100,  1010302,  1010100,  1010302,  1010100,  1010302,\n",
       "        1010100,  1010302,  1010100,  1010100,  1010100,  1010100,\n",
       "        1010302,  1010302,  1010302,  1010302,  1010302,  1010302,\n",
       "        1010302,  1010200,  1010200,  1010200, 22010010,  2010001,\n",
       "       21010100,  2010001, 20000103, 22010010,  2010001, 21010100,\n",
       "        2010001, 20000103, 20010103, 22010100, 22210100,  2020001,\n",
       "        2020001, 22010010,  2040000,  2010001, 20000103, 22010100,\n",
       "       22210100,  2020001,  2020001, 22010010,  2040000,  2010001,\n",
       "       22010100, 22210100,  2020001,  2020001, 22010010,  2040000,\n",
       "        2010001, 22010100, 22210100,  2020001,  2020001, 22010010,\n",
       "        2040000,  2010001,  1013000, 20000103,    10010,        0,\n",
       "        1013000,  1000000,  1000000,  1000000,  1000000,  1000000,\n",
       "        1000000, 41000001,  1001010, 41000001,        0,  3010020,\n",
       "         120000,  1011120,  1013000,  2010000,  2010002,  2010001,\n",
       "          10010,        0,        0,        0,        0,        0,\n",
       "              0,        0,        0,        0,        0,        0,\n",
       "              0, 22010010,  1000000, 22010010, 41000001,  1001010,\n",
       "       41000001,        0,    10011,   120000,  1011120,  1013000,\n",
       "       22010010, 41000001,  1001010, 41000001,        0, 21010004,\n",
       "         120000,  1011120,  1013000, 22010010, 21010004,   120000,\n",
       "        1011120,  1013000, 22010010, 21010004,   120000,  1011120,\n",
       "        1013000, 22010010, 21010004,   120000,  1011120,  1013000,\n",
       "       22010010, 21010004,   120000,  1011120,  1013000, 22010010,\n",
       "       21010004, 21010004, 21010004,    10100, 21010004, 41000001,\n",
       "        1001010, 41000001,        0, 22011000, 22011000,    10100,\n",
       "       22011000,    10100, 22011000,    10100, 22011000,   120000,\n",
       "        1011120,  1013000,  1000000, 22010010, 22011000,   120000,\n",
       "        1011120,  1013000,  1000000, 22010010, 22011000,   120000,\n",
       "        1011120,  1013000, 22010010,  1000000, 22010010, 22011000,\n",
       "         120000,  1011120,  1013000, 22010010, 22011000,   120000,\n",
       "        1011120,  1013000, 22010010, 22011000,   120000,  1011120,\n",
       "        1013000, 22010010, 22011000, 22011000, 22011000,    10100,\n",
       "       22011000,    10100, 22011000,    10100, 22011000,   120000,\n",
       "        1011120,  1013000, 22010010, 22011000,   120000,  1011120,\n",
       "        1013000, 22010010, 22011000,   120000,  1011120,  1013000,\n",
       "        1000000, 22010010, 22011000,   120000,  1011120,  1013000,\n",
       "       22010010, 22011000,   120000,  1011120,  1013000, 22010010,\n",
       "       22011000,   120000,  1011120,  1013000, 22010010, 22011000,\n",
       "       22011000, 22011000,    10100, 22011000,    10100, 22011000,\n",
       "          10100, 22011000,   120000,  1011120,  1013000, 22010010,\n",
       "       22011000,   120000,  1011120,  1013000, 22010010, 22011000,\n",
       "         120000,  1011120,  1013000, 22010010, 22011000,   120000,\n",
       "        1011120,  1013000, 22010010, 22011000,   120000,  1011120,\n",
       "        1013000, 22010010, 22011000,   120000,  1011120,  1013000,\n",
       "        1000000, 22010010, 22011000, 22010010, 20110000, 22010010,\n",
       "        2010001,  2020001, 22010010, 20110000,  2020001, 62010000,\n",
       "        1000000, 22010010], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot each string features, then one-hot the overall (Should be done before padding & normalizing the data)\n",
    "def onehot(input): \n",
    "    df = pd.DataFrame(data=input)\n",
    "    ohot = df.apply(lambda x: pd.factorize(x)[0])\n",
    "    return np.array(ohot)\n",
    "\n",
    "# For loop for all examples\n",
    "APIname = pd.DataFrame(data=xtrain[0,:,:8])\n",
    "\n",
    "code = onehot(APIname) # onehot by features\n",
    "\n",
    "for i in range(8):\n",
    "    APIname_code += 10**i*code[:,i]\n",
    "APIname_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0],\n",
       "       [ 1],\n",
       "       [ 2],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 3],\n",
       "       [ 0],\n",
       "       [ 5],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 3],\n",
       "       [ 0],\n",
       "       [ 6],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 3],\n",
       "       [ 0],\n",
       "       [ 7],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 3],\n",
       "       [ 0],\n",
       "       [ 8],\n",
       "       [ 6],\n",
       "       [ 7],\n",
       "       [ 8],\n",
       "       [ 6],\n",
       "       [ 7],\n",
       "       [ 8],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 3],\n",
       "       [ 0],\n",
       "       [ 6],\n",
       "       [ 7],\n",
       "       [ 8],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 3],\n",
       "       [ 0],\n",
       "       [ 9],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 3],\n",
       "       [ 0],\n",
       "       [10],\n",
       "       [11],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [11],\n",
       "       [11],\n",
       "       [11],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [13],\n",
       "       [ 0],\n",
       "       [11],\n",
       "       [11],\n",
       "       [ 8],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [11],\n",
       "       [ 8],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [ 0],\n",
       "       [14],\n",
       "       [11],\n",
       "       [11],\n",
       "       [ 8],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [ 4],\n",
       "       [ 0],\n",
       "       [15],\n",
       "       [11],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [15],\n",
       "       [ 8],\n",
       "       [ 0],\n",
       "       [11],\n",
       "       [11],\n",
       "       [16],\n",
       "       [14],\n",
       "       [17],\n",
       "       [14],\n",
       "       [ 0],\n",
       "       [18],\n",
       "       [19],\n",
       "       [19],\n",
       "       [20],\n",
       "       [16],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [11],\n",
       "       [12],\n",
       "       [12],\n",
       "       [21],\n",
       "       [11],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [ 4],\n",
       "       [ 0],\n",
       "       [ 8],\n",
       "       [14],\n",
       "       [ 0],\n",
       "       [22],\n",
       "       [14],\n",
       "       [23],\n",
       "       [19],\n",
       "       [16],\n",
       "       [14],\n",
       "       [22],\n",
       "       [14],\n",
       "       [23],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [21],\n",
       "       [19],\n",
       "       [23],\n",
       "       [21],\n",
       "       [14],\n",
       "       [14],\n",
       "       [24],\n",
       "       [16],\n",
       "       [25],\n",
       "       [16],\n",
       "       [26],\n",
       "       [14],\n",
       "       [21],\n",
       "       [ 0],\n",
       "       [21],\n",
       "       [11],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [11],\n",
       "       [12],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [11],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [11],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [11],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [11],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [11],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [ 4],\n",
       "       [ 0],\n",
       "       [11],\n",
       "       [11],\n",
       "       [11],\n",
       "       [11],\n",
       "       [11],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [11],\n",
       "       [11],\n",
       "       [11],\n",
       "       [11],\n",
       "       [12],\n",
       "       [11],\n",
       "       [12],\n",
       "       [11],\n",
       "       [12],\n",
       "       [11],\n",
       "       [12],\n",
       "       [11],\n",
       "       [12],\n",
       "       [11],\n",
       "       [12],\n",
       "       [11],\n",
       "       [11],\n",
       "       [11],\n",
       "       [11],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [16],\n",
       "       [14],\n",
       "       [17],\n",
       "       [14],\n",
       "       [21],\n",
       "       [16],\n",
       "       [14],\n",
       "       [17],\n",
       "       [14],\n",
       "       [21],\n",
       "       [27],\n",
       "       [23],\n",
       "       [28],\n",
       "       [29],\n",
       "       [29],\n",
       "       [16],\n",
       "       [30],\n",
       "       [14],\n",
       "       [21],\n",
       "       [23],\n",
       "       [28],\n",
       "       [29],\n",
       "       [29],\n",
       "       [16],\n",
       "       [30],\n",
       "       [14],\n",
       "       [23],\n",
       "       [28],\n",
       "       [29],\n",
       "       [29],\n",
       "       [16],\n",
       "       [30],\n",
       "       [14],\n",
       "       [23],\n",
       "       [28],\n",
       "       [29],\n",
       "       [29],\n",
       "       [16],\n",
       "       [30],\n",
       "       [14],\n",
       "       [31],\n",
       "       [21],\n",
       "       [32],\n",
       "       [ 0],\n",
       "       [31],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 3],\n",
       "       [ 0],\n",
       "       [33],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [34],\n",
       "       [35],\n",
       "       [14],\n",
       "       [32],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [16],\n",
       "       [ 1],\n",
       "       [16],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 3],\n",
       "       [ 0],\n",
       "       [20],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 3],\n",
       "       [ 0],\n",
       "       [36],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [36],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [36],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [36],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [36],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [36],\n",
       "       [36],\n",
       "       [36],\n",
       "       [ 5],\n",
       "       [36],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 3],\n",
       "       [ 0],\n",
       "       [37],\n",
       "       [37],\n",
       "       [ 5],\n",
       "       [37],\n",
       "       [ 5],\n",
       "       [37],\n",
       "       [ 5],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [ 1],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [ 1],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [ 1],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [37],\n",
       "       [37],\n",
       "       [37],\n",
       "       [ 5],\n",
       "       [37],\n",
       "       [ 5],\n",
       "       [37],\n",
       "       [ 5],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [ 1],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [37],\n",
       "       [37],\n",
       "       [37],\n",
       "       [ 5],\n",
       "       [37],\n",
       "       [ 5],\n",
       "       [37],\n",
       "       [ 5],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [ 1],\n",
       "       [16],\n",
       "       [37],\n",
       "       [16],\n",
       "       [38],\n",
       "       [16],\n",
       "       [14],\n",
       "       [29],\n",
       "       [16],\n",
       "       [38],\n",
       "       [29],\n",
       "       [39],\n",
       "       [ 1],\n",
       "       [16]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot(APIname_code) \n",
    "# This onehot to be shared among all data samples\n",
    "# Purpose: Certain combination are only shown by malwares\n",
    "# Need more weight on this part, still figuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0, 1110, 2110,    0,    0,    0,    0, 2110,    0,    0,    0,\n",
       "          0, 3121,    0,    0,    0,    0, 3121,    0,    0,    0,    0,\n",
       "       3121, 3121, 3121, 3121, 3121, 3121, 3121,    0,    0,    0,    0,\n",
       "       3121, 3121, 3121,    0,    0,    0,    0, 3130,    0,    0,    0,\n",
       "          0, 2100, 3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121,\n",
       "       3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121,\n",
       "       3121, 3121, 3121, 3121, 3121, 3121, 2110,    0, 3121, 3121, 3121,\n",
       "       3121, 3121, 3121, 3121, 3121, 3121, 3121,    0,    0, 3121, 3121,\n",
       "       3121, 3121, 3121, 3121,    0,    0, 3121, 3121, 3121, 3121, 3121,\n",
       "       3121,    0, 3121, 3121, 2110,    0, 2110,    0,    0, 2100, 1201,\n",
       "       1201, 2110, 2110,    0,    0, 3121, 3121, 3121, 3342, 3121, 3121,\n",
       "       3121, 3121, 3121, 3121, 3121, 3121, 3121,    0,    0, 3121,    0,\n",
       "          0, 1201,    0, 1201, 1201, 2110,    0, 1201,    0, 1201,    0,\n",
       "          0, 3342, 1201, 1201, 3342,    0,    0, 1201, 2110, 2110, 2110,\n",
       "       2110,    0, 3342,    0, 3342, 3121, 3121, 3121, 3121, 3121, 3121,\n",
       "       3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121,\n",
       "       3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121,\n",
       "       3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121,\n",
       "       3121, 3121, 3121, 3121, 3121, 3121,    0,    0, 3121, 3121, 3121,\n",
       "       3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121,\n",
       "       3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121,\n",
       "       3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121, 3121,\n",
       "       3121, 3121, 2110,    0, 2110,    0, 3342, 2110,    0, 2110,    0,\n",
       "       3342, 2110, 2110, 2110, 1201, 1201, 2110, 1201,    0, 3342, 2110,\n",
       "       2110, 1201, 1201, 2110, 1201,    0, 2110, 2110, 1201, 1201, 2110,\n",
       "       1201,    0, 2110, 2110, 1201, 1201, 2110, 1201,    0, 2100, 3342,\n",
       "          0,    0, 2100, 1110, 1110, 1110, 1110, 1110, 1110,    0,    0,\n",
       "          0,    0, 1110, 3130, 2100, 2100, 3121, 3121,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "       3342, 1110, 3342,    0,    0,    0,    0, 2110, 3130, 2100, 2100,\n",
       "       3342,    0,    0,    0,    0, 2110, 3130, 2100, 2100, 3342, 2110,\n",
       "       3130, 2100, 2100, 3342, 2110, 3130, 2100, 2100, 3342, 2110, 3130,\n",
       "       2100, 2100, 3342, 2110, 3130, 2100, 2100, 3342, 2110, 2110, 2110,\n",
       "       2110, 2110,    0,    0,    0,    0, 2110, 2110, 2110, 2110, 2110,\n",
       "       2110, 2110, 2110, 3130, 2100, 2100, 1110, 3342, 2110, 3130, 2100,\n",
       "       2100, 1110, 3342, 2110, 3130, 2100, 2100, 3342, 1110, 3342, 2110,\n",
       "       3130, 2100, 2100, 3342, 2110, 3130, 2100, 2100, 3342, 2110, 3130,\n",
       "       2100, 2100, 3342, 2110, 2110, 2110, 2110, 2110, 2110, 2110, 2110,\n",
       "       2110, 3130, 2100, 2100, 3342, 2110, 3130, 2100, 2100, 3342, 2110,\n",
       "       3130, 2100, 2100, 1110, 3342, 2110, 3130, 2100, 2100, 3342, 2110,\n",
       "       3130, 2100, 2100, 3342, 2110, 3130, 2100, 2100, 3342, 2110, 2110,\n",
       "       2110, 2110, 2110, 2110, 2110, 2110, 2110, 3130, 2100, 2100, 3342,\n",
       "       2110, 3130, 2100, 2100, 3342, 2110, 3130, 2100, 2100, 3342, 2110,\n",
       "       3130, 2100, 2100, 3342, 2110, 3130, 2100, 2100, 3342, 2110, 3130,\n",
       "       2100, 2100, 1110, 3342, 2110, 2110, 2110, 2110,    0, 1201, 2110,\n",
       "       2110, 1201, 2110, 1110, 3342], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For loop for all examples\n",
    "APIcat = pd.DataFrame(data=xtrain[0,:,8:12])\n",
    "\n",
    "code = onehot(APIcat) # onehot by features\n",
    "\n",
    "APIcat_code = np.zeros_like(code[:,0])\n",
    "for i in range(4):\n",
    "    APIcat_code += 10**i*code[:,i]\n",
    "APIcat_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0],\n",
       "       [ 1],\n",
       "       [ 2],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 3],\n",
       "       [ 0],\n",
       "       [ 5],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 3],\n",
       "       [ 0],\n",
       "       [ 6],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 3],\n",
       "       [ 0],\n",
       "       [ 7],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 3],\n",
       "       [ 0],\n",
       "       [ 8],\n",
       "       [ 6],\n",
       "       [ 7],\n",
       "       [ 8],\n",
       "       [ 6],\n",
       "       [ 7],\n",
       "       [ 8],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 3],\n",
       "       [ 0],\n",
       "       [ 6],\n",
       "       [ 7],\n",
       "       [ 8],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 3],\n",
       "       [ 0],\n",
       "       [ 9],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 3],\n",
       "       [ 0],\n",
       "       [10],\n",
       "       [11],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [11],\n",
       "       [11],\n",
       "       [11],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [13],\n",
       "       [ 0],\n",
       "       [11],\n",
       "       [11],\n",
       "       [ 8],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [11],\n",
       "       [ 8],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [ 0],\n",
       "       [14],\n",
       "       [11],\n",
       "       [11],\n",
       "       [ 8],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [ 4],\n",
       "       [ 0],\n",
       "       [15],\n",
       "       [11],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [15],\n",
       "       [ 8],\n",
       "       [ 0],\n",
       "       [11],\n",
       "       [11],\n",
       "       [16],\n",
       "       [14],\n",
       "       [17],\n",
       "       [14],\n",
       "       [ 0],\n",
       "       [18],\n",
       "       [19],\n",
       "       [19],\n",
       "       [20],\n",
       "       [16],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [11],\n",
       "       [12],\n",
       "       [12],\n",
       "       [21],\n",
       "       [11],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [ 4],\n",
       "       [ 0],\n",
       "       [ 8],\n",
       "       [14],\n",
       "       [ 0],\n",
       "       [22],\n",
       "       [14],\n",
       "       [23],\n",
       "       [19],\n",
       "       [16],\n",
       "       [14],\n",
       "       [22],\n",
       "       [14],\n",
       "       [23],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [21],\n",
       "       [19],\n",
       "       [23],\n",
       "       [21],\n",
       "       [14],\n",
       "       [14],\n",
       "       [24],\n",
       "       [16],\n",
       "       [25],\n",
       "       [16],\n",
       "       [26],\n",
       "       [14],\n",
       "       [21],\n",
       "       [ 0],\n",
       "       [21],\n",
       "       [11],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [11],\n",
       "       [12],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [11],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [11],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [11],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [11],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [11],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [ 4],\n",
       "       [ 0],\n",
       "       [11],\n",
       "       [11],\n",
       "       [11],\n",
       "       [11],\n",
       "       [11],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [ 8],\n",
       "       [11],\n",
       "       [11],\n",
       "       [11],\n",
       "       [11],\n",
       "       [11],\n",
       "       [12],\n",
       "       [11],\n",
       "       [12],\n",
       "       [11],\n",
       "       [12],\n",
       "       [11],\n",
       "       [12],\n",
       "       [11],\n",
       "       [12],\n",
       "       [11],\n",
       "       [12],\n",
       "       [11],\n",
       "       [11],\n",
       "       [11],\n",
       "       [11],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [12],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [16],\n",
       "       [14],\n",
       "       [17],\n",
       "       [14],\n",
       "       [21],\n",
       "       [16],\n",
       "       [14],\n",
       "       [17],\n",
       "       [14],\n",
       "       [21],\n",
       "       [27],\n",
       "       [23],\n",
       "       [28],\n",
       "       [29],\n",
       "       [29],\n",
       "       [16],\n",
       "       [30],\n",
       "       [14],\n",
       "       [21],\n",
       "       [23],\n",
       "       [28],\n",
       "       [29],\n",
       "       [29],\n",
       "       [16],\n",
       "       [30],\n",
       "       [14],\n",
       "       [23],\n",
       "       [28],\n",
       "       [29],\n",
       "       [29],\n",
       "       [16],\n",
       "       [30],\n",
       "       [14],\n",
       "       [23],\n",
       "       [28],\n",
       "       [29],\n",
       "       [29],\n",
       "       [16],\n",
       "       [30],\n",
       "       [14],\n",
       "       [31],\n",
       "       [21],\n",
       "       [32],\n",
       "       [ 0],\n",
       "       [31],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 3],\n",
       "       [ 0],\n",
       "       [33],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [34],\n",
       "       [35],\n",
       "       [14],\n",
       "       [32],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [16],\n",
       "       [ 1],\n",
       "       [16],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 3],\n",
       "       [ 0],\n",
       "       [20],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 3],\n",
       "       [ 0],\n",
       "       [36],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [36],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [36],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [36],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [36],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [36],\n",
       "       [36],\n",
       "       [36],\n",
       "       [ 5],\n",
       "       [36],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 3],\n",
       "       [ 0],\n",
       "       [37],\n",
       "       [37],\n",
       "       [ 5],\n",
       "       [37],\n",
       "       [ 5],\n",
       "       [37],\n",
       "       [ 5],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [ 1],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [ 1],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [ 1],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [37],\n",
       "       [37],\n",
       "       [37],\n",
       "       [ 5],\n",
       "       [37],\n",
       "       [ 5],\n",
       "       [37],\n",
       "       [ 5],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [ 1],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [37],\n",
       "       [37],\n",
       "       [37],\n",
       "       [ 5],\n",
       "       [37],\n",
       "       [ 5],\n",
       "       [37],\n",
       "       [ 5],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [16],\n",
       "       [37],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [31],\n",
       "       [ 1],\n",
       "       [16],\n",
       "       [37],\n",
       "       [16],\n",
       "       [38],\n",
       "       [16],\n",
       "       [14],\n",
       "       [29],\n",
       "       [16],\n",
       "       [38],\n",
       "       [29],\n",
       "       [39],\n",
       "       [ 1],\n",
       "       [16]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot(APIname_code) \n",
    "# This onehot to be shared among all data samples\n",
    "# Purpose: Certain combination are only shown by malwares\n",
    "# Need more weight on this part, still figuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "ytrain = np.array(df_train['Label'])\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 500, 75)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 500, 6)            2256      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 250, 6)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 250, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 250, 16)           496       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 125, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 125, 16)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 120)               240120    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 170       \n",
      "=================================================================\n",
      "Total params: 253,206\n",
      "Trainable params: 253,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "inputs = keras.Input(shape=(xtrain.shape[1], xtrain.shape[2])) \n",
    "x = keras.layers.Conv1D(filters=6, kernel_size=5, padding='same', activation='relu')(inputs)\n",
    "x = keras.layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = keras.layers.Dropout(0.4)(x)\n",
    "x = keras.layers.Conv1D(filters=16, kernel_size=5, padding='same', activation='relu')(x)\n",
    "x = keras.layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = keras.layers.Dropout(0.4)(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(120, activation='relu')(x)\n",
    "x = keras.layers.Dense(84, activation='relu')(x)\n",
    "x = keras.layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# Take a look at the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18662 samples\n",
      "Epoch 1/40\n",
      "18662/18662 [==============================] - 18s 985us/sample - loss: 0.3191 - accuracy: 0.8633\n",
      "Epoch 2/40\n",
      "18662/18662 [==============================] - 18s 945us/sample - loss: 0.2204 - accuracy: 0.9119\n",
      "Epoch 3/40\n",
      "18662/18662 [==============================] - 16s 849us/sample - loss: 0.1978 - accuracy: 0.9227\n",
      "Epoch 4/40\n",
      "18662/18662 [==============================] - 16s 839us/sample - loss: 0.1815 - accuracy: 0.9274\n",
      "Epoch 5/40\n",
      "18662/18662 [==============================] - 16s 839us/sample - loss: 0.1751 - accuracy: 0.9306\n",
      "Epoch 6/40\n",
      "18662/18662 [==============================] - 16s 841us/sample - loss: 0.1617 - accuracy: 0.9366\n",
      "Epoch 7/40\n",
      "18662/18662 [==============================] - 16s 880us/sample - loss: 0.1534 - accuracy: 0.9379\n",
      "Epoch 8/40\n",
      "18662/18662 [==============================] - 16s 855us/sample - loss: 0.1483 - accuracy: 0.9418\n",
      "Epoch 9/40\n",
      "18662/18662 [==============================] - 16s 852us/sample - loss: 0.1448 - accuracy: 0.9425\n",
      "Epoch 10/40\n",
      "18662/18662 [==============================] - 17s 888us/sample - loss: 0.1392 - accuracy: 0.9455\n",
      "Epoch 11/40\n",
      "18662/18662 [==============================] - 16s 841us/sample - loss: 0.1334 - accuracy: 0.9473\n",
      "Epoch 12/40\n",
      "18662/18662 [==============================] - 16s 844us/sample - loss: 0.1296 - accuracy: 0.9483\n",
      "Epoch 13/40\n",
      "18662/18662 [==============================] - 17s 894us/sample - loss: 0.1243 - accuracy: 0.9518\n",
      "Epoch 14/40\n",
      "18662/18662 [==============================] - 16s 852us/sample - loss: 0.1182 - accuracy: 0.9540\n",
      "Epoch 15/40\n",
      "18662/18662 [==============================] - 16s 851us/sample - loss: 0.1174 - accuracy: 0.9539\n",
      "Epoch 16/40\n",
      "18662/18662 [==============================] - 16s 845us/sample - loss: 0.1128 - accuracy: 0.9542\n",
      "Epoch 17/40\n",
      "18662/18662 [==============================] - 16s 847us/sample - loss: 0.1112 - accuracy: 0.9573\n",
      "Epoch 18/40\n",
      "18662/18662 [==============================] - 16s 849us/sample - loss: 0.1053 - accuracy: 0.9595\n",
      "Epoch 19/40\n",
      "18662/18662 [==============================] - 16s 846us/sample - loss: 0.1059 - accuracy: 0.9599\n",
      "Epoch 20/40\n",
      "18662/18662 [==============================] - 16s 849us/sample - loss: 0.1018 - accuracy: 0.9614\n",
      "Epoch 21/40\n",
      "18662/18662 [==============================] - 16s 851us/sample - loss: 0.1025 - accuracy: 0.9602\n",
      "Epoch 22/40\n",
      "18662/18662 [==============================] - 16s 860us/sample - loss: 0.0956 - accuracy: 0.9631\n",
      "Epoch 23/40\n",
      "18662/18662 [==============================] - 16s 852us/sample - loss: 0.0936 - accuracy: 0.9642\n",
      "Epoch 24/40\n",
      "18662/18662 [==============================] - 16s 850us/sample - loss: 0.0911 - accuracy: 0.9663\n",
      "Epoch 25/40\n",
      "18662/18662 [==============================] - 16s 867us/sample - loss: 0.0917 - accuracy: 0.9651\n",
      "Epoch 26/40\n",
      "18662/18662 [==============================] - 16s 864us/sample - loss: 0.0890 - accuracy: 0.9668\n",
      "Epoch 27/40\n",
      "18662/18662 [==============================] - 16s 849us/sample - loss: 0.0903 - accuracy: 0.9649\n",
      "Epoch 28/40\n",
      "18662/18662 [==============================] - 16s 852us/sample - loss: 0.0814 - accuracy: 0.9694\n",
      "Epoch 29/40\n",
      "18662/18662 [==============================] - 16s 851us/sample - loss: 0.0883 - accuracy: 0.9669\n",
      "Epoch 30/40\n",
      "18662/18662 [==============================] - 16s 855us/sample - loss: 0.0832 - accuracy: 0.9689\n",
      "Epoch 31/40\n",
      "18662/18662 [==============================] - 16s 850us/sample - loss: 0.0825 - accuracy: 0.9687\n",
      "Epoch 32/40\n",
      "18662/18662 [==============================] - 17s 901us/sample - loss: 0.0820 - accuracy: 0.9696\n",
      "Epoch 33/40\n",
      "18662/18662 [==============================] - 16s 852us/sample - loss: 0.0856 - accuracy: 0.9688\n",
      "Epoch 34/40\n",
      "18662/18662 [==============================] - 16s 852us/sample - loss: 0.0813 - accuracy: 0.9701\n",
      "Epoch 35/40\n",
      "18662/18662 [==============================] - 16s 856us/sample - loss: 0.0755 - accuracy: 0.9711\n",
      "Epoch 36/40\n",
      "18662/18662 [==============================] - 16s 857us/sample - loss: 0.0767 - accuracy: 0.9715\n",
      "Epoch 37/40\n",
      "18662/18662 [==============================] - 16s 859us/sample - loss: 0.0744 - accuracy: 0.9716\n",
      "Epoch 38/40\n",
      "18662/18662 [==============================] - 16s 852us/sample - loss: 0.0777 - accuracy: 0.9703\n",
      "Epoch 39/40\n",
      "18662/18662 [==============================] - 16s 853us/sample - loss: 0.0764 - accuracy: 0.9723\n",
      "Epoch 40/40\n",
      "18662/18662 [==============================] - 16s 852us/sample - loss: 0.0717 - accuracy: 0.9740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x11ce73512b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "model.fit(xtrain, to_categorical(ytrain), epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Load data + Process + Pad\n",
    "xtest = np.load('testdata.npy',allow_pickle=True)\n",
    "xtest = process(xtest)\n",
    "xtest = pad_data(xtest)\n",
    "\n",
    "ytest = model.predict(xtest)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Predicted'] = ytest[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('Normalized_w_DataLength.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
