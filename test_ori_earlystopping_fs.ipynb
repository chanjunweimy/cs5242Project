{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18632</th>\n",
       "      <td>18632</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18633</th>\n",
       "      <td>18633</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18634</th>\n",
       "      <td>18634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18635</th>\n",
       "      <td>18635</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18636</th>\n",
       "      <td>18636</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18637</th>\n",
       "      <td>18637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18638</th>\n",
       "      <td>18638</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18639</th>\n",
       "      <td>18639</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18640</th>\n",
       "      <td>18640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18641</th>\n",
       "      <td>18641</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18642</th>\n",
       "      <td>18642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18643</th>\n",
       "      <td>18643</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18644</th>\n",
       "      <td>18644</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18645</th>\n",
       "      <td>18645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18646</th>\n",
       "      <td>18646</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18647</th>\n",
       "      <td>18647</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18648</th>\n",
       "      <td>18648</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18649</th>\n",
       "      <td>18649</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18650</th>\n",
       "      <td>18650</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18651</th>\n",
       "      <td>18651</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18652</th>\n",
       "      <td>18652</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18653</th>\n",
       "      <td>18653</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18654</th>\n",
       "      <td>18654</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18655</th>\n",
       "      <td>18655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18656</th>\n",
       "      <td>18656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18657</th>\n",
       "      <td>18657</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18658</th>\n",
       "      <td>18658</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18659</th>\n",
       "      <td>18659</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18660</th>\n",
       "      <td>18660</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18661</th>\n",
       "      <td>18661</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18662 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id  Label\n",
       "0          0      1\n",
       "1          1      0\n",
       "2          2      0\n",
       "3          3      1\n",
       "4          4      0\n",
       "5          5      1\n",
       "6          6      0\n",
       "7          7      1\n",
       "8          8      0\n",
       "9          9      0\n",
       "10        10      1\n",
       "11        11      0\n",
       "12        12      1\n",
       "13        13      1\n",
       "14        14      0\n",
       "15        15      1\n",
       "16        16      0\n",
       "17        17      1\n",
       "18        18      1\n",
       "19        19      1\n",
       "20        20      1\n",
       "21        21      1\n",
       "22        22      1\n",
       "23        23      1\n",
       "24        24      0\n",
       "25        25      1\n",
       "26        26      1\n",
       "27        27      0\n",
       "28        28      0\n",
       "29        29      1\n",
       "...      ...    ...\n",
       "18632  18632      0\n",
       "18633  18633      1\n",
       "18634  18634      1\n",
       "18635  18635      0\n",
       "18636  18636      0\n",
       "18637  18637      0\n",
       "18638  18638      0\n",
       "18639  18639      0\n",
       "18640  18640      0\n",
       "18641  18641      0\n",
       "18642  18642      0\n",
       "18643  18643      1\n",
       "18644  18644      0\n",
       "18645  18645      0\n",
       "18646  18646      0\n",
       "18647  18647      0\n",
       "18648  18648      0\n",
       "18649  18649      0\n",
       "18650  18650      1\n",
       "18651  18651      0\n",
       "18652  18652      0\n",
       "18653  18653      0\n",
       "18654  18654      1\n",
       "18655  18655      0\n",
       "18656  18656      0\n",
       "18657  18657      1\n",
       "18658  18658      0\n",
       "18659  18659      0\n",
       "18660  18660      1\n",
       "18661  18661      1\n",
       "\n",
       "[18662 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('train_kaggle.csv')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.distplot(df_train['Label']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_dataframe(id):\n",
    "    train_data = np.load(\"train/train/{}.npy\".format(id))\n",
    "    return pd.DataFrame(data=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_dataframe(id):\n",
    "    test_data = np.load(\"test/test/{}.npy\".format(id))\n",
    "    return pd.DataFrame(data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_data(df):\n",
    "    total = df.isnull().sum().sort_values(ascending=False)\n",
    "    percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    return missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_missing_data(df, missing_indices):\n",
    "    df = df.drop(missing_indices,1)\n",
    "    # for col in df_temp.columns:\n",
    "    #    df = df.drop(df.loc[df[col].isnull()].index)\n",
    "    count = df.isnull().sum().max() #just checking that there's no missing data missing...\n",
    "    if count > 0:\n",
    "        print(count)\n",
    "        return pd.DataFrame()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18662,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dataframes = np.load('allData.npy', allow_pickle = True)\n",
    "dataframes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_SIZE = 500\n",
    "\n",
    "def pad_data(dfs):\n",
    "    data = []\n",
    "    for i in range(len(dfs)):\n",
    "        df = dfs[i]\n",
    "        diff = PAD_SIZE - df.shape[0]\n",
    "        if diff > 0:\n",
    "            df = np.pad(df, [(0, diff), (0,0)], 'constant')\n",
    "        else:\n",
    "            df = df[:PAD_SIZE]\n",
    "        data.append(df)\n",
    "    data = np.stack(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18662, 500, 102)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain = pad_data(dataframes)\n",
    "XTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_padded.npy', XTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 102)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18662,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = df_train['Label'].values\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.417022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.720324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.302333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.146756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.092339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.186260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.345561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.396767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.538817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.419195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.685220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.204452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.878117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.027388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.670468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.417305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.558690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.140387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.198101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.800745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.968262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.313424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.692323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.876389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.894607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.085044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.039055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.169830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.878143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6021</th>\n",
       "      <td>6021</td>\n",
       "      <td>0.303023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6022</th>\n",
       "      <td>6022</td>\n",
       "      <td>0.035078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6023</th>\n",
       "      <td>6023</td>\n",
       "      <td>0.590051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6024</th>\n",
       "      <td>6024</td>\n",
       "      <td>0.701621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6025</th>\n",
       "      <td>6025</td>\n",
       "      <td>0.669988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6026</th>\n",
       "      <td>6026</td>\n",
       "      <td>0.356210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6027</th>\n",
       "      <td>6027</td>\n",
       "      <td>0.111645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6028</th>\n",
       "      <td>6028</td>\n",
       "      <td>0.641320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6029</th>\n",
       "      <td>6029</td>\n",
       "      <td>0.063197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6030</th>\n",
       "      <td>6030</td>\n",
       "      <td>0.644363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6031</th>\n",
       "      <td>6031</td>\n",
       "      <td>0.835289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6032</th>\n",
       "      <td>6032</td>\n",
       "      <td>0.057159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6033</th>\n",
       "      <td>6033</td>\n",
       "      <td>0.355870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6034</th>\n",
       "      <td>6034</td>\n",
       "      <td>0.618719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035</th>\n",
       "      <td>6035</td>\n",
       "      <td>0.638601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>6036</td>\n",
       "      <td>0.197939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>6037</td>\n",
       "      <td>0.623363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>6038</td>\n",
       "      <td>0.557541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>6039</td>\n",
       "      <td>0.885718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6040</th>\n",
       "      <td>6040</td>\n",
       "      <td>0.697025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6041</th>\n",
       "      <td>6041</td>\n",
       "      <td>0.364263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6042</th>\n",
       "      <td>6042</td>\n",
       "      <td>0.225348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>6043</td>\n",
       "      <td>0.610909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6044</th>\n",
       "      <td>6044</td>\n",
       "      <td>0.255565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6045</th>\n",
       "      <td>6045</td>\n",
       "      <td>0.075813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6046</th>\n",
       "      <td>6046</td>\n",
       "      <td>0.822702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6047</th>\n",
       "      <td>6047</td>\n",
       "      <td>0.227952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6048</th>\n",
       "      <td>6048</td>\n",
       "      <td>0.379553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049</th>\n",
       "      <td>6049</td>\n",
       "      <td>0.846487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6050</th>\n",
       "      <td>6050</td>\n",
       "      <td>0.103151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6051 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  Predicted\n",
       "0        0   0.417022\n",
       "1        1   0.720324\n",
       "2        2   0.000114\n",
       "3        3   0.302333\n",
       "4        4   0.146756\n",
       "5        5   0.092339\n",
       "6        6   0.186260\n",
       "7        7   0.345561\n",
       "8        8   0.396767\n",
       "9        9   0.538817\n",
       "10      10   0.419195\n",
       "11      11   0.685220\n",
       "12      12   0.204452\n",
       "13      13   0.878117\n",
       "14      14   0.027388\n",
       "15      15   0.670468\n",
       "16      16   0.417305\n",
       "17      17   0.558690\n",
       "18      18   0.140387\n",
       "19      19   0.198101\n",
       "20      20   0.800745\n",
       "21      21   0.968262\n",
       "22      22   0.313424\n",
       "23      23   0.692323\n",
       "24      24   0.876389\n",
       "25      25   0.894607\n",
       "26      26   0.085044\n",
       "27      27   0.039055\n",
       "28      28   0.169830\n",
       "29      29   0.878143\n",
       "...    ...        ...\n",
       "6021  6021   0.303023\n",
       "6022  6022   0.035078\n",
       "6023  6023   0.590051\n",
       "6024  6024   0.701621\n",
       "6025  6025   0.669988\n",
       "6026  6026   0.356210\n",
       "6027  6027   0.111645\n",
       "6028  6028   0.641320\n",
       "6029  6029   0.063197\n",
       "6030  6030   0.644363\n",
       "6031  6031   0.835289\n",
       "6032  6032   0.057159\n",
       "6033  6033   0.355870\n",
       "6034  6034   0.618719\n",
       "6035  6035   0.638601\n",
       "6036  6036   0.197939\n",
       "6037  6037   0.623363\n",
       "6038  6038   0.557541\n",
       "6039  6039   0.885718\n",
       "6040  6040   0.697025\n",
       "6041  6041   0.364263\n",
       "6042  6042   0.225348\n",
       "6043  6043   0.610909\n",
       "6044  6044   0.255565\n",
       "6045  6045   0.075813\n",
       "6046  6046   0.822702\n",
       "6047  6047   0.227952\n",
       "6048  6048   0.379553\n",
       "6049  6049   0.846487\n",
       "6050  6050   0.103151\n",
       "\n",
       "[6051 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('sample_solution.csv')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdatas = []\n",
    "for id in df_test['Id']:\n",
    "    dfi = load_test_dataframe(id)\n",
    "    testdatas.append(dfi.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6051\n"
     ]
    }
   ],
   "source": [
    "print(len(testdatas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTest = pad_data(np.array(testdatas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('test_padded.npy', XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6051, 500, 102)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 8),\n",
       " (8, 12),\n",
       " (12, 28),\n",
       " (28, 44),\n",
       " (44, 52),\n",
       " (52, 64),\n",
       " (64, 80),\n",
       " (80, 92),\n",
       " (92, 102)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\n",
    "    (0, 8),\n",
    "    (8, 12),\n",
    "    (12, 28),\n",
    "    (28, 44),\n",
    "    (44, 52),\n",
    "    (52, 64),\n",
    "    (64, 80),\n",
    "    (80, 92),\n",
    "    (92, 102)\n",
    "]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(XTrain, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "def select_model(trainShape):\n",
    "    METRICS = [\n",
    "          keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "          keras.metrics.AUC(name='auc'),\n",
    "    ]\n",
    "\n",
    "    inputs = keras.Input(shape=(trainShape[1], trainShape[2])) \n",
    "    x = keras.layers.Conv1D(filters=6, kernel_size=5, padding='same', activation='relu')(inputs)\n",
    "    x = keras.layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = keras.layers.Dropout(0.4)(x)\n",
    "    x = keras.layers.Conv1D(filters=16, kernel_size=5, padding='same', activation='relu')(x)\n",
    "    x = keras.layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = keras.layers.Dropout(0.4)(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(120, activation='relu')(x)\n",
    "    x = keras.layers.Dense(84, activation='relu')(x)\n",
    "    x = keras.layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer='adam',\n",
    "                 metrics=METRICS)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_es():\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_auc', \n",
    "        verbose=1,\n",
    "        patience=10,\n",
    "        mode='max',\n",
    "        restore_best_weights=True)\n",
    "    return early_stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16795 samples, validate on 1867 samples\n",
      "Epoch 1/2\n",
      "16795/16795 [==============================] - 28s 2ms/sample - loss: 0.6065 - accuracy: 0.8058 - auc: 0.8711 - val_loss: 0.3826 - val_accuracy: 0.8586 - val_auc: 0.9285\n",
      "Epoch 2/2\n",
      "16795/16795 [==============================] - 27s 2ms/sample - loss: 0.3601 - accuracy: 0.8475 - auc: 0.9242 - val_loss: 0.3107 - val_accuracy: 0.8784 - val_auc: 0.9499\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "EPOCHS = 100\n",
    "firstModel = select_model(XTrain.shape)\n",
    "baseline_history = firstModel.fit(\n",
    "    X_train,\n",
    "    to_categorical(y_train),\n",
    "    epochs=2,\n",
    "    callbacks = [select_es()],\n",
    "    validation_data=(X_val, to_categorical(y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9499407"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(baseline_history.history['val_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9499407,\n",
       " None,\n",
       " <tensorflow.python.keras.engine.training.Model at 0x25ae5741908>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btHist = (np.max(baseline_history.history['val_auc']), None, firstModel)\n",
    "btHist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True]\n",
      "Train on 16795 samples, validate on 1867 samples\n",
      "Epoch 1/35\n",
      "16795/16795 [==============================] - 49s 3ms/sample - loss: 0.4572 - accuracy: 0.8229 - auc: 0.8957 - val_loss: 0.3084 - val_accuracy: 0.8763 - val_auc: 0.9461\n",
      "Epoch 2/35\n",
      "16795/16795 [==============================] - 48s 3ms/sample - loss: 0.3025 - accuracy: 0.8662 - auc: 0.9449 - val_loss: 0.2501 - val_accuracy: 0.8864 - val_auc: 0.9627\n",
      "Epoch 3/35\n",
      "16795/16795 [==============================] - 49s 3ms/sample - loss: 0.2605 - accuracy: 0.8842 - auc: 0.9586 - val_loss: 0.2251 - val_accuracy: 0.9031 - val_auc: 0.9696\n",
      "Epoch 4/35\n",
      "16795/16795 [==============================] - 48s 3ms/sample - loss: 0.2358 - accuracy: 0.8971 - auc: 0.9662 - val_loss: 0.2152 - val_accuracy: 0.9138 - val_auc: 0.9724\n",
      "Epoch 5/35\n",
      "16795/16795 [==============================] - 51s 3ms/sample - loss: 0.2210 - accuracy: 0.9022 - auc: 0.9701 - val_loss: 0.1980 - val_accuracy: 0.9234 - val_auc: 0.9775\n",
      "Epoch 6/35\n",
      "16795/16795 [==============================] - 51s 3ms/sample - loss: 0.2096 - accuracy: 0.9076 - auc: 0.9731 - val_loss: 0.1893 - val_accuracy: 0.9202 - val_auc: 0.9787\n",
      "Epoch 7/35\n",
      "16795/16795 [==============================] - 50s 3ms/sample - loss: 0.1961 - accuracy: 0.9176 - auc: 0.9769 - val_loss: 0.1917 - val_accuracy: 0.9159 - val_auc: 0.9777\n",
      "Epoch 8/35\n",
      "16795/16795 [==============================] - 50s 3ms/sample - loss: 0.1835 - accuracy: 0.9215 - auc: 0.9795 - val_loss: 0.1740 - val_accuracy: 0.9288 - val_auc: 0.9819\n",
      "Epoch 9/35\n",
      "16795/16795 [==============================] - 51s 3ms/sample - loss: 0.1737 - accuracy: 0.9268 - auc: 0.9816 - val_loss: 0.1684 - val_accuracy: 0.9298 - val_auc: 0.9837\n",
      "Epoch 10/35\n",
      "16795/16795 [==============================] - 51s 3ms/sample - loss: 0.1659 - accuracy: 0.9327 - auc: 0.9830 - val_loss: 0.1609 - val_accuracy: 0.9400 - val_auc: 0.9857\n",
      "Epoch 11/35\n",
      "16795/16795 [==============================] - 51s 3ms/sample - loss: 0.1584 - accuracy: 0.9327 - auc: 0.9847 - val_loss: 0.1601 - val_accuracy: 0.9373 - val_auc: 0.9849\n",
      "Epoch 12/35\n",
      "16795/16795 [==============================] - 52s 3ms/sample - loss: 0.1532 - accuracy: 0.9356 - auc: 0.9855 - val_loss: 0.1790 - val_accuracy: 0.9298 - val_auc: 0.9805\n",
      "Epoch 13/35\n",
      "16795/16795 [==============================] - 53s 3ms/sample - loss: 0.1521 - accuracy: 0.9369 - auc: 0.9857 - val_loss: 0.1567 - val_accuracy: 0.9395 - val_auc: 0.9859\n",
      "Epoch 14/35\n",
      "16795/16795 [==============================] - 53s 3ms/sample - loss: 0.1470 - accuracy: 0.9400 - auc: 0.9868 - val_loss: 0.1610 - val_accuracy: 0.9373 - val_auc: 0.9837\n",
      "Epoch 15/35\n",
      "16795/16795 [==============================] - 55s 3ms/sample - loss: 0.1408 - accuracy: 0.9440 - auc: 0.9877 - val_loss: 0.1580 - val_accuracy: 0.9379 - val_auc: 0.9850\n",
      "Epoch 16/35\n",
      "16795/16795 [==============================] - 53s 3ms/sample - loss: 0.1425 - accuracy: 0.9434 - auc: 0.9875 - val_loss: 0.1731 - val_accuracy: 0.9341 - val_auc: 0.9820\n",
      "Epoch 17/35\n",
      "16795/16795 [==============================] - 54s 3ms/sample - loss: 0.1334 - accuracy: 0.9459 - auc: 0.9889 - val_loss: 0.1624 - val_accuracy: 0.9330 - val_auc: 0.9832\n",
      "Epoch 18/35\n",
      "16795/16795 [==============================] - 59s 3ms/sample - loss: 0.1298 - accuracy: 0.9478 - auc: 0.9895 - val_loss: 0.1636 - val_accuracy: 0.9347 - val_auc: 0.9837\n",
      "Epoch 19/35\n",
      "16795/16795 [==============================] - 60s 4ms/sample - loss: 0.1260 - accuracy: 0.9480 - auc: 0.9900 - val_loss: 0.1485 - val_accuracy: 0.9384 - val_auc: 0.9868\n",
      "Epoch 20/35\n",
      "16795/16795 [==============================] - 62s 4ms/sample - loss: 0.1205 - accuracy: 0.9515 - auc: 0.9908 - val_loss: 0.1582 - val_accuracy: 0.9357 - val_auc: 0.9851\n",
      "Epoch 21/35\n",
      "16795/16795 [==============================] - 63s 4ms/sample - loss: 0.1169 - accuracy: 0.9521 - auc: 0.9915 - val_loss: 0.1533 - val_accuracy: 0.9363 - val_auc: 0.9852\n",
      "Epoch 22/35\n",
      "16795/16795 [==============================] - 56s 3ms/sample - loss: 0.1107 - accuracy: 0.9539 - auc: 0.9923 - val_loss: 0.1646 - val_accuracy: 0.9368 - val_auc: 0.9839\n",
      "Epoch 23/35\n",
      "16795/16795 [==============================] - 61s 4ms/sample - loss: 0.1111 - accuracy: 0.9548 - auc: 0.9920 - val_loss: 0.1636 - val_accuracy: 0.9379 - val_auc: 0.9844\n",
      "Epoch 24/35\n",
      "16795/16795 [==============================] - 61s 4ms/sample - loss: 0.1151 - accuracy: 0.9536 - auc: 0.9915 - val_loss: 0.1543 - val_accuracy: 0.9395 - val_auc: 0.9852\n",
      "Epoch 25/35\n",
      "16795/16795 [==============================] - 63s 4ms/sample - loss: 0.1092 - accuracy: 0.9564 - auc: 0.9924 - val_loss: 0.1610 - val_accuracy: 0.9368 - val_auc: 0.9843\n",
      "Epoch 26/35\n",
      "16795/16795 [==============================] - 65s 4ms/sample - loss: 0.1081 - accuracy: 0.9565 - auc: 0.9926 - val_loss: 0.1701 - val_accuracy: 0.9384 - val_auc: 0.9828\n",
      "Epoch 27/35\n",
      "16795/16795 [==============================] - 68s 4ms/sample - loss: 0.1061 - accuracy: 0.9573 - auc: 0.9928 - val_loss: 0.1473 - val_accuracy: 0.9405 - val_auc: 0.9865\n",
      "Epoch 28/35\n",
      "16795/16795 [==============================] - 69s 4ms/sample - loss: 0.1067 - accuracy: 0.9565 - auc: 0.9929 - val_loss: 0.1545 - val_accuracy: 0.9379 - val_auc: 0.9846\n",
      "Epoch 29/35\n",
      "16768/16795 [============================>.] - ETA: 0s - loss: 0.1072 - accuracy: 0.9592 - auc: 0.9930Restoring model weights from the end of the best epoch.\n",
      "16795/16795 [==============================] - 67s 4ms/sample - loss: 0.1071 - accuracy: 0.9592 - auc: 0.9931 - val_loss: 0.1785 - val_accuracy: 0.9400 - val_auc: 0.9815\n",
      "Epoch 00029: early stopping\n",
      "0.98676157\n",
      "[ True  True  True  True  True  True  True  True False]\n",
      "Train on 16795 samples, validate on 1867 samples\n",
      "Epoch 1/35\n",
      "16795/16795 [==============================] - 64s 4ms/sample - loss: 0.3346 - accuracy: 0.8520 - auc: 0.9312 - val_loss: 0.2649 - val_accuracy: 0.8961 - val_auc: 0.9637\n",
      "Epoch 2/35\n",
      "16795/16795 [==============================] - 60s 4ms/sample - loss: 0.2452 - accuracy: 0.8932 - auc: 0.9633 - val_loss: 0.2269 - val_accuracy: 0.9143 - val_auc: 0.9752\n",
      "Epoch 3/35\n",
      "16795/16795 [==============================] - 61s 4ms/sample - loss: 0.2132 - accuracy: 0.9096 - auc: 0.9724 - val_loss: 0.2205 - val_accuracy: 0.9111 - val_auc: 0.9734\n",
      "Epoch 4/35\n",
      "16795/16795 [==============================] - 59s 4ms/sample - loss: 0.1959 - accuracy: 0.9159 - auc: 0.9768 - val_loss: 0.2163 - val_accuracy: 0.9218 - val_auc: 0.9792\n",
      "Epoch 5/35\n",
      "16795/16795 [==============================] - 58s 3ms/sample - loss: 0.1762 - accuracy: 0.9250 - auc: 0.9810 - val_loss: 0.1828 - val_accuracy: 0.9293 - val_auc: 0.9831\n",
      "Epoch 6/35\n",
      "16795/16795 [==============================] - 58s 3ms/sample - loss: 0.1673 - accuracy: 0.9291 - auc: 0.9828 - val_loss: 0.1919 - val_accuracy: 0.9197 - val_auc: 0.9790\n",
      "Epoch 7/35\n",
      "16795/16795 [==============================] - 58s 3ms/sample - loss: 0.1573 - accuracy: 0.9352 - auc: 0.9847 - val_loss: 0.1735 - val_accuracy: 0.9282 - val_auc: 0.9830\n",
      "Epoch 8/35\n",
      "16795/16795 [==============================] - 61s 4ms/sample - loss: 0.1503 - accuracy: 0.9366 - auc: 0.9861 - val_loss: 0.1674 - val_accuracy: 0.9314 - val_auc: 0.9840\n",
      "Epoch 9/35\n",
      "16795/16795 [==============================] - 56s 3ms/sample - loss: 0.1466 - accuracy: 0.9412 - auc: 0.9867 - val_loss: 0.1637 - val_accuracy: 0.9368 - val_auc: 0.9851\n",
      "Epoch 10/35\n",
      "  960/16795 [>.............................] - ETA: 50s - loss: 0.1446 - accuracy: 0.9396 - auc: 0.9873"
     ]
    }
   ],
   "source": [
    "def select_features(features, selected, n):\n",
    "    if n >= len(features):\n",
    "        x_trainp = None\n",
    "        x_valp = None\n",
    "        hasSelected = False\n",
    "        for i in range(n):\n",
    "            if selected[i] == False:\n",
    "                continue\n",
    "            x_train_i = X_train[:,:, features[i][0]: features[i][1]]\n",
    "            x_val_i = X_val[:,:, features[i][0]: features[i][1]]\n",
    "            if hasSelected == False:\n",
    "                x_trainp = x_train_i\n",
    "                x_valp = x_val_i\n",
    "                hasSelected = True\n",
    "            else:                \n",
    "                x_trainp = np.concatenate((x_trainp, x_train_i), axis=2)\n",
    "                x_valp = np.concatenate((x_valp, x_val_i), axis=2)\n",
    "        if hasSelected == True:\n",
    "            EPOCHS = 35\n",
    "            print(selected)\n",
    "            model = select_model(x_trainp.shape)\n",
    "            baseline_history = model.fit(\n",
    "                x_trainp,\n",
    "                to_categorical(y_train),\n",
    "                epochs=EPOCHS,\n",
    "                callbacks = [select_es()],\n",
    "                validation_data=(x_valp, to_categorical(y_val)))                \n",
    "            val_auc = np.max(baseline_history.history['val_auc'])\n",
    "            print(val_auc)\n",
    "            return (val_auc, selected, model)\n",
    "        return (0, None, None)\n",
    "    selected[n] = True\n",
    "    hist1 = select_features(features, selected, n + 1)\n",
    "    selected[n] = False\n",
    "    hist2 = select_features(features, selected, n + 1)\n",
    "    if hist1[0] > hist2[0]:\n",
    "        return hist1\n",
    "    return hist2\n",
    "select_features(features, np.ones(len(features), dtype=bool), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bestHistory[0])\n",
    "print(bestHistory[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YTest = bestHistory[2].predict(XTest)\n",
    "YTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Predicted'] = YTest[:, 0]\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
