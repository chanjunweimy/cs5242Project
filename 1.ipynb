{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "xtrain = np.load('traindata.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(18662):\n",
    "    if xtrain[i][:,64:92].sum(axis=0).sum() != 0:\n",
    "        print(i, 'with label', df_train['Label'][i], 'is not equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "def load_train_dataframe(id):\n",
    "    train_data = np.load(\"train/train/{}.npy\".format(id))\n",
    "    return pd.DataFrame(data=train_data)\n",
    "def load_test_dataframe(id):\n",
    "    test_data = np.load(\"test/test/{}.npy\".format(id))\n",
    "    return pd.DataFrame(data=test_data)\n",
    "\n",
    "# load training\n",
    "traindata = []\n",
    "for id in df_train['Id']:\n",
    "    dfi = load_train_dataframe(id)\n",
    "    traindata.append(dfi.values)\n",
    "print('Done train')\n",
    "# load test\n",
    "testdata = []\n",
    "for id in df_test['Id']:\n",
    "    dfi = load_test_dataframe(id)\n",
    "    testdata.append(dfi.values)\n",
    "print('Done test')\n",
    "\n",
    "np.save('traindata.npy', traindata)\n",
    "\n",
    "np.save('testdata.npy', testdata)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "training data:  (18662, 2) \n",
      "test data:  (6051, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print('Done')\n",
    "df_train = pd.read_csv('train_kaggle.csv')\n",
    "df_test = pd.read_csv('sample_solution.csv')\n",
    "\n",
    "print('training data: ',df_train.shape,'\\ntest data: ', df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(dfs):\n",
    "    data = []\n",
    "    length = 12\n",
    "    for df in dfs:\n",
    "        out = np.zeros((df.shape[0],length))\n",
    "#         out[:,0:length] = df[:,0:8] #1\n",
    "#         out[:,0:length] = df[:,8:12] #2\n",
    "#         out[:,0:length] = df[:,12:28] #3\n",
    "#         out[:,0:length] = df[:,28:44] #4\n",
    "#         out[:,0:length] = df[:,44:52] #5\n",
    "#         out[:,0:length] = df[:,52:64] #6\n",
    "#         out[:,0:length] = df[:,64:80] #7\n",
    "#         out[:,0:length] = df[:,80:92] #8\n",
    "#         out[:,0:length] = df[:,92:102] #9\n",
    "\n",
    "        data.append(out)                 \n",
    "    return data\n",
    "\n",
    "def pad_data(dfs):\n",
    "    padsize = 1000\n",
    "    data = []\n",
    "    for df in dfs:\n",
    "        diff = padsize-df.shape[0]\n",
    "        if diff >0:\n",
    "            df = np.pad(df, [(0, diff), (0,0)], 'constant')\n",
    "        else:\n",
    "            df = df[-padsize:]\n",
    "        data.append(df)\n",
    "        \n",
    "    data = np.stack(data)\n",
    "    return data\n",
    "\n",
    "# Load data + Process + Pad\n",
    "xtrain = np.load('traindata.npy',allow_pickle=True)\n",
    "xtrain = process(xtrain)\n",
    "xtrain = pad_data(xtrain)\n",
    "# xtest = np.load('testdata.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "ytrain = np.array(df_train['Label'])\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18662, 1000, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain, X_val, ytrain, y_val = train_test_split(xtrain, ytrain, test_size=0.2, random_state=42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_metrics(history):\n",
    "    metrics =  ['loss', 'auc', 'precision', 'recall']\n",
    "    for n, metric in enumerate(metrics):\n",
    "        name = metric.replace(\"_\",\" \").capitalize()\n",
    "        plt.subplot(2,2,n+1)\n",
    "        plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')\n",
    "        plt.plot(history.epoch, history.history['val_'+metric],\n",
    "                 color=colors[0], linestyle=\"--\", label='Val')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(name)\n",
    "        if metric == 'loss':\n",
    "            plt.ylim([0, plt.ylim()[1]])\n",
    "        elif metric == 'auc':\n",
    "            plt.ylim([0.8,1])\n",
    "        else:\n",
    "            plt.ylim([0,1])\n",
    "\n",
    "        plt.legend()\n",
    "        \n",
    "import sklearn\n",
    "def plot_roc(name, labels, predictions, **kwargs):\n",
    "    fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n",
    "\n",
    "    plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('False positives [%]')\n",
    "    plt.ylabel('True positives [%]')\n",
    "    plt.xlim([-0.5,20])\n",
    "    plt.ylim([80,100.5])\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1000, 12)]        0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 1000, 6)           366       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 500, 6)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 500, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 16)           496       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 250, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 250, 16)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4000)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 120)               480120    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 85        \n",
      "=================================================================\n",
      "Total params: 491,231\n",
      "Trainable params: 491,231\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "inputs = keras.Input(shape=(xtrain.shape[1], xtrain.shape[2])) \n",
    "x = keras.layers.Conv1D(filters=6, kernel_size=5, padding='same', activation='relu')(inputs)\n",
    "x = keras.layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = keras.layers.Dropout(0.4)(x)\n",
    "x = keras.layers.Conv1D(filters=16, kernel_size=5, padding='same', activation='relu')(x)\n",
    "x = keras.layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = keras.layers.Dropout(0.4)(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(120, activation='relu')(x)\n",
    "x = keras.layers.Dense(84, activation='relu')(x)\n",
    "x = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#              optimizer='adam',\n",
    "#              metrics=['accuracy'])\n",
    "\n",
    "model.compile(\n",
    "      optimizer=keras.optimizers.Adam(),\n",
    "      loss=keras.losses.BinaryCrossentropy(),\n",
    "      metrics=METRICS)\n",
    "\n",
    "# Take a look at the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_auc', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14929 samples, validate on 3733 samples\n",
      "Epoch 1/100\n",
      "14929/14929 [==============================] - 13s 849us/sample - loss: 0.6820 - accuracy: 0.5639 - auc: 0.5161 - val_loss: 0.6805 - val_accuracy: 0.5631 - val_auc: 0.5154\n",
      "Epoch 2/100\n",
      "14929/14929 [==============================] - 11s 762us/sample - loss: 0.6762 - accuracy: 0.5651 - auc: 0.5283 - val_loss: 0.6789 - val_accuracy: 0.5620 - val_auc: 0.5170\n",
      "Epoch 3/100\n",
      "14929/14929 [==============================] - 12s 775us/sample - loss: 0.6743 - accuracy: 0.5657 - auc: 0.5216 - val_loss: 0.6808 - val_accuracy: 0.5631 - val_auc: 0.5168\n",
      "Epoch 4/100\n",
      "14929/14929 [==============================] - 12s 784us/sample - loss: 0.6711 - accuracy: 0.5680 - auc: 0.5195 - val_loss: 0.6790 - val_accuracy: 0.5612 - val_auc: 0.5178\n",
      "Epoch 5/100\n",
      "14929/14929 [==============================] - 11s 742us/sample - loss: 0.6689 - accuracy: 0.5692 - auc: 0.5343 - val_loss: 0.6816 - val_accuracy: 0.5628 - val_auc: 0.5213\n",
      "Epoch 6/100\n",
      "14929/14929 [==============================] - 12s 777us/sample - loss: 0.6668 - accuracy: 0.5697 - auc: 0.5364 - val_loss: 0.6823 - val_accuracy: 0.5631 - val_auc: 0.5226\n",
      "Epoch 7/100\n",
      "14929/14929 [==============================] - 11s 750us/sample - loss: 0.6662 - accuracy: 0.5716 - auc: 0.5360 - val_loss: 0.6839 - val_accuracy: 0.5617 - val_auc: 0.5201\n",
      "Epoch 8/100\n",
      "14929/14929 [==============================] - 11s 737us/sample - loss: 0.6621 - accuracy: 0.5732 - auc: 0.5391 - val_loss: 0.6919 - val_accuracy: 0.5612 - val_auc: 0.5213\n",
      "Epoch 9/100\n",
      "14929/14929 [==============================] - 11s 743us/sample - loss: 0.6619 - accuracy: 0.5736 - auc: 0.5387 - val_loss: 0.6877 - val_accuracy: 0.5609 - val_auc: 0.5217\n",
      "Epoch 10/100\n",
      "14929/14929 [==============================] - 12s 780us/sample - loss: 0.6595 - accuracy: 0.5755 - auc: 0.5456 - val_loss: 0.6959 - val_accuracy: 0.5615 - val_auc: 0.5238\n",
      "Epoch 11/100\n",
      "14929/14929 [==============================] - 13s 866us/sample - loss: 0.6597 - accuracy: 0.5751 - auc: 0.5393 - val_loss: 0.6839 - val_accuracy: 0.5604 - val_auc: 0.5227\n",
      "Epoch 12/100\n",
      "14929/14929 [==============================] - 12s 781us/sample - loss: 0.6605 - accuracy: 0.5762 - auc: 0.5366 - val_loss: 0.6940 - val_accuracy: 0.5601 - val_auc: 0.5193\n",
      "Epoch 13/100\n",
      "14929/14929 [==============================] - 13s 862us/sample - loss: 0.6590 - accuracy: 0.5763 - auc: 0.5458 - val_loss: 0.7000 - val_accuracy: 0.5604 - val_auc: 0.5220\n",
      "Epoch 14/100\n",
      "14929/14929 [==============================] - 11s 763us/sample - loss: 0.6583 - accuracy: 0.5765 - auc: 0.5370 - val_loss: 0.7013 - val_accuracy: 0.5612 - val_auc: 0.5237\n",
      "Epoch 15/100\n",
      "14929/14929 [==============================] - 11s 738us/sample - loss: 0.6578 - accuracy: 0.5774 - auc: 0.5445 - val_loss: 0.7058 - val_accuracy: 0.5601 - val_auc: 0.5218\n",
      "Epoch 16/100\n",
      "14929/14929 [==============================] - 11s 748us/sample - loss: 0.6574 - accuracy: 0.5768 - auc: 0.5457 - val_loss: 0.7087 - val_accuracy: 0.5623 - val_auc: 0.5245\n",
      "Epoch 17/100\n",
      "14929/14929 [==============================] - 11s 744us/sample - loss: 0.6555 - accuracy: 0.5785 - auc: 0.5525 - val_loss: 0.7051 - val_accuracy: 0.5599 - val_auc: 0.5215\n",
      "Epoch 18/100\n",
      "14929/14929 [==============================] - 11s 731us/sample - loss: 0.6562 - accuracy: 0.5776 - auc: 0.5427 - val_loss: 0.7085 - val_accuracy: 0.5623 - val_auc: 0.5234\n",
      "Epoch 19/100\n",
      "14929/14929 [==============================] - 11s 733us/sample - loss: 0.6556 - accuracy: 0.5783 - auc: 0.5435 - val_loss: 0.7134 - val_accuracy: 0.5599 - val_auc: 0.5224\n",
      "Epoch 20/100\n",
      "14929/14929 [==============================] - 12s 782us/sample - loss: 0.6559 - accuracy: 0.5775 - auc: 0.5397 - val_loss: 0.7167 - val_accuracy: 0.5612 - val_auc: 0.5228\n",
      "Epoch 21/100\n",
      "14929/14929 [==============================] - 11s 743us/sample - loss: 0.6541 - accuracy: 0.5785 - auc: 0.5520 - val_loss: 0.7299 - val_accuracy: 0.5607 - val_auc: 0.5220\n",
      "Epoch 22/100\n",
      "14929/14929 [==============================] - 11s 726us/sample - loss: 0.6556 - accuracy: 0.5789 - auc: 0.5511 - val_loss: 0.7087 - val_accuracy: 0.5599 - val_auc: 0.5214\n",
      "Epoch 23/100\n",
      "14929/14929 [==============================] - 11s 738us/sample - loss: 0.6545 - accuracy: 0.5759 - auc: 0.5569 - val_loss: 0.7058 - val_accuracy: 0.5607 - val_auc: 0.5240\n",
      "Epoch 24/100\n",
      "14929/14929 [==============================] - 14s 959us/sample - loss: 0.6549 - accuracy: 0.5785 - auc: 0.5425 - val_loss: 0.7253 - val_accuracy: 0.5607 - val_auc: 0.5214\n",
      "Epoch 25/100\n",
      "14929/14929 [==============================] - 11s 759us/sample - loss: 0.6569 - accuracy: 0.5783 - auc: 0.5397 - val_loss: 0.7124 - val_accuracy: 0.5612 - val_auc: 0.5233\n",
      "Epoch 26/100\n",
      "14912/14929 [============================>.] - ETA: 0s - loss: 0.6604 - accuracy: 0.5788 - auc: 0.5438Restoring model weights from the end of the best epoch.\n",
      "14929/14929 [==============================] - 11s 731us/sample - loss: 0.6604 - accuracy: 0.5788 - auc: 0.5439 - val_loss: 0.7171 - val_accuracy: 0.5612 - val_auc: 0.5225\n",
      "Epoch 00026: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "EPOCHS = 100\n",
    "baseline_history = model.fit(\n",
    "    xtrain,\n",
    "    ytrain,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks = [early_stopping],\n",
    "    validation_data=(X_val, y_val))\n",
    "\n",
    "# model.fit(xtrain, to_categorical(ytrain), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Load data + Process + Pad\n",
    "xtest = np.load('testdata.npy',allow_pickle=True)\n",
    "xtest = process(xtest)\n",
    "xtest = pad_data(xtest)\n",
    "\n",
    "ytest = model.predict(xtest)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6021</th>\n",
       "      <td>6021</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6022</th>\n",
       "      <td>6022</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6023</th>\n",
       "      <td>6023</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6024</th>\n",
       "      <td>6024</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6025</th>\n",
       "      <td>6025</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6026</th>\n",
       "      <td>6026</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6027</th>\n",
       "      <td>6027</td>\n",
       "      <td>0.019742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6028</th>\n",
       "      <td>6028</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6029</th>\n",
       "      <td>6029</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6030</th>\n",
       "      <td>6030</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6031</th>\n",
       "      <td>6031</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6032</th>\n",
       "      <td>6032</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6033</th>\n",
       "      <td>6033</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6034</th>\n",
       "      <td>6034</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035</th>\n",
       "      <td>6035</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>6036</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>6037</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>6038</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>6039</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6040</th>\n",
       "      <td>6040</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6041</th>\n",
       "      <td>6041</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6042</th>\n",
       "      <td>6042</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>6043</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6044</th>\n",
       "      <td>6044</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6045</th>\n",
       "      <td>6045</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6046</th>\n",
       "      <td>6046</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6047</th>\n",
       "      <td>6047</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6048</th>\n",
       "      <td>6048</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049</th>\n",
       "      <td>6049</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6050</th>\n",
       "      <td>6050</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6051 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  Predicted\n",
       "0        0   0.549826\n",
       "1        1   0.549826\n",
       "2        2   0.549826\n",
       "3        3   0.549826\n",
       "4        4   0.549826\n",
       "5        5   0.549826\n",
       "6        6   0.549826\n",
       "7        7   0.549826\n",
       "8        8   0.549826\n",
       "9        9   0.549826\n",
       "10      10   0.549826\n",
       "11      11   0.549826\n",
       "12      12   1.000000\n",
       "13      13   0.549826\n",
       "14      14   0.549826\n",
       "15      15   0.549826\n",
       "16      16   0.549826\n",
       "17      17   1.000000\n",
       "18      18   0.549826\n",
       "19      19   0.549826\n",
       "20      20   0.549826\n",
       "21      21   0.549826\n",
       "22      22   0.549826\n",
       "23      23   0.549826\n",
       "24      24   0.549826\n",
       "25      25   0.549826\n",
       "26      26   0.549826\n",
       "27      27   0.549826\n",
       "28      28   0.549826\n",
       "29      29   0.549826\n",
       "...    ...        ...\n",
       "6021  6021   0.549826\n",
       "6022  6022   0.549826\n",
       "6023  6023   0.549826\n",
       "6024  6024   0.549826\n",
       "6025  6025   0.549826\n",
       "6026  6026   0.549826\n",
       "6027  6027   0.019742\n",
       "6028  6028   0.549826\n",
       "6029  6029   0.549826\n",
       "6030  6030   0.549826\n",
       "6031  6031   0.549826\n",
       "6032  6032   0.549826\n",
       "6033  6033   0.549826\n",
       "6034  6034   0.549826\n",
       "6035  6035   0.549826\n",
       "6036  6036   0.549826\n",
       "6037  6037   0.549826\n",
       "6038  6038   0.549826\n",
       "6039  6039   0.549826\n",
       "6040  6040   0.549826\n",
       "6041  6041   0.549826\n",
       "6042  6042   0.549826\n",
       "6043  6043   0.549826\n",
       "6044  6044   0.549826\n",
       "6045  6045   0.549826\n",
       "6046  6046   0.549826\n",
       "6047  6047   0.549826\n",
       "6048  6048   0.549826\n",
       "6049  6049   0.549826\n",
       "6050  6050   0.549826\n",
       "\n",
       "[6051 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['Predicted'] = ytest[:, 0]\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('8_full.csv', index=False) # Better to be global onehot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
